{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d558a23-be31-4464-a37d-94cd582b5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from pyDOE import lhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400ee52-23cd-4a98-9ea6-95f615082cab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Schrodinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc777856-70ef-46cd-9526-1095cfc51549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import load_data\n",
    "\n",
    "\n",
    "def read_data_fn(root_path):\n",
    "    data = load_data(root_path, \"NLS.mat\")\n",
    "    exact = data[\"uu\"]\n",
    "    exact_u = np.real(exact)\n",
    "    exact_v = np.imag(exact)\n",
    "    return data, [exact_u, exact_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367f16c-8191-416e-abfd-26c38559e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, [exact_u] = read_data_fn(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9e7af-e18d-493e-a389-6d824fc3df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.domains.spatial import Interval\n",
    "from src.data.domains.time import TimeDomain\n",
    "from src.data.mesh.mesh import Mesh\n",
    "from src.data.pinn_datamodule import PINNDataModule\n",
    "from src.data.sampler.boundary_condition import PeriodicBoundaryCondition\n",
    "from src.data.sampler.initial_condition import InitialCondition\n",
    "from src.data.sampler.mesh_sampler import MeshSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8fe40-7399-4f6a-a161-c0a4149c4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TimeDomain([0, 1.57079633], 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8b463-2163-4a5d-9e1e-b04c007fb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = Interval([-5, 4.9609375], [256, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f1474-3231-44f2-92b4-cfdcf189a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(\n",
    "    root_dir=\"data\",\n",
    "    time_domain=td,\n",
    "    spatial_domain=sd,\n",
    "    read_data_fn=read_data_fn,\n",
    "    lb=[-5.0, 0.0],\n",
    "    ub=[5.0, 1.57079633],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8b41d-2801-4813-b92e-39f20a49da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = mesh.on_initial_boundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e8af1-3f43-4985-b687-a9c454272c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.solution[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1375b-047c-415c-a32d-7af23b3ee692",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, t.shape, u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc959ac-b991-4c2c-999f-2553349ac99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = PeriodicBoundaryCondition(mesh, num_sample=50, derivative_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d80ad-dad1-4ea7-9924-3b63f0d1ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = InitialCondition(mesh, num_sample=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15d29b-62e0-47a2-a496-23d5071acfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MeshSampler(mesh, num_sample=20000, use_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e07fd4-c3e0-4794-b84e-4722f73c0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = MeshSampler(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217093b3-27e0-4c95-bf01-d94b5e18376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = f[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538f414-5780-4726-a0ca-01190e84d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].min(), x[0].max(), t.min(), t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da5e35-046f-42cd-a84b-e07126adb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a71d1-31fa-47bf-852d-97994dc7d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "noise = 0.0\n",
    "\n",
    "N_u = 100\n",
    "N_f = 10000\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t = data[\"t\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"]).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = Exact[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = Exact[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = Exact[:, -1:]\n",
    "\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea9a5b-e2ca-4907-9c60-dd341b08a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, t1 = ic[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8681f4-1975-4095-9039-5f9db7a87234",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840196cf-2c2c-43c9-be48-974408f25a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_star, v_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf69d5b-b01a-474a-8a83-10911791dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = val[:]\n",
    "plt.plot(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beaf08b-82aa-42ee-ad47-424863f2ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star[:, 0], x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51623ca5-9e55-42f9-882a-e4c6f5f8fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_star[:, 0][:, None] - x[0])\n",
    "print(X_star[:, 1][:, None] - t)\n",
    "print(np.sum(np.square(X_star[:, 1][:, None] - t)))\n",
    "print(u_star - u[:, 0][:, None])\n",
    "print(v_star - u[:, 1][:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15fcc3-8a24-4cd7-a403-d8789b076dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = ic[:]\n",
    "print(x0 - x[0])\n",
    "print(t0 - t)\n",
    "print(u0 - u[:, 0][:, None])\n",
    "print(v0 - u[:, 1][:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506af6b-9e71-4e9f-905f-461c1c5d88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, t1, t2 = pb[:]\n",
    "print(x1 - x_ub)\n",
    "print(x2 - x_lb)\n",
    "print(t1 - t_ub)\n",
    "print(t2 - t_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67017719-1b1f-44fa-85cc-d5bd2956670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f, t_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914defeb-5c39-41f3-9a6e-4cc22f9bdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = f[:]\n",
    "print(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af760f38-a561-4b6d-b883-6b7ff4b609ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].min(), x[0].max(), t.min(), t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339e895-0679-4048-909b-4025a8940d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f.min(), x_f.max(), t_f.min(), t_f.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e284c-ab25-473d-92ad-a0fe72dac739",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee806692-7c41-44b0-9348-25e5b899d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0] - X_star[:, 0][:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac00340-cbf0-4cbb-809f-cfc918936a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "u[:, 0][:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228633cc-2d17-4737-911b-0c193b90f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_star - u[:, 0][:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7825a0d-ed1c-4334-911c-57d46ce3ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PINNDataModule(train_datasets=[ic, pb, f], val_dataset=val, batch_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5af569-2e9b-440f-a53e-c84dccf89724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0d77c-6f15-44d2-b22f-cee4283e0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaf79d-a918-4dca-b36a-a230fbe1d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(a[\"InitialCondition\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492c562-19fc-4397-b697-6f1d4ad67812",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc24e1-9ab7-40af-bd74-ca2083101d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(x[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1cbed-ce7d-4409-b52a-502436bf6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_points = 201\n",
    "shape = (256, 1)\n",
    "x_interval = [-5, 4.9609375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b27d7-cae1-4f89-97ff-877f00321546",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_interval[0], x_interval[1], num=shape[0])\n",
    "mesh = np.tile(x, (t_points, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8e388-e5ba-4b4e-b534-80fdbcb15b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = [0, 1.57079633]\n",
    "time = np.linspace(time_interval[0], time_interval[1], num=t_points)\n",
    "spatial_points = 256\n",
    "\n",
    "mesh = np.tile(time, (spatial_points, 1)).T[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cd274-67ee-4e57-87c1-93da1a76a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ab54d-db03-46ff-9f5f-dbdb773a9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a9b5f-530f-43ee-9b1e-d4c8bdd75fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_star[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc70d4-656f-4de1-bed5-801190ce8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TT[:, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae4c8d-367a-49fb-9032-7347e31f4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2b67b-c3d6-4b93-94a1-76436f6800a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea28e8b-13c8-4d4d-9ebd-4c25e40ebb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24aa67b-4e9a-4315-8391-079729acda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import lhs\n",
    "\n",
    "noise = 0.0\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi / 2])\n",
    "\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 20000\n",
    "layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "data = scipy.io.loadmat(\"data/NLS.mat\")\n",
    "\n",
    "t = data[\"tt\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = data[\"uu\"]\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2)\n",
    "print(Exact_u.shape, Exact_v.shape)\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact_u.T.flatten()[:, None]\n",
    "v_star = Exact_v.T.flatten()[:, None]\n",
    "h_star = Exact_h.T.flatten()[:, None]\n",
    "\n",
    "###########################\n",
    "\n",
    "idx_x = np.random.choice(x.shape[0], 50, replace=False)\n",
    "x0 = x[idx_x, :]\n",
    "u0 = Exact_u[idx_x, 0:1]\n",
    "v0 = Exact_v[idx_x, 0:1]\n",
    "print(u0.shape, v0.shape)\n",
    "\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "tb = t[idx_t, :]\n",
    "\n",
    "X_f = lb + (ub - lb) * lhs(2, N_f)\n",
    "\n",
    "\n",
    "X0 = np.concatenate((x0, 0 * x0), 1)  # (x0, 0)\n",
    "X_lb = np.concatenate((0 * tb + lb[0], tb), 1)  # (lb[0], tb)\n",
    "X_ub = np.concatenate((0 * tb + ub[0], tb), 1)  # (ub[0], tb)\n",
    "\n",
    "lb = lb\n",
    "ub = ub\n",
    "\n",
    "x0 = X0[:, 0:1]\n",
    "t0 = X0[:, 1:2]\n",
    "\n",
    "x_lb = X_lb[:, 0:1]\n",
    "t_lb = X_lb[:, 1:2]\n",
    "print(x_lb.shape, t_lb.shape)\n",
    "\n",
    "\n",
    "x_ub = X_ub[:, 0:1]\n",
    "t_ub = X_ub[:, 1:2]\n",
    "\n",
    "x_f = X_f[:, 0:1]\n",
    "t_f = X_f[:, 1:2]\n",
    "\n",
    "u0 = u0\n",
    "v0 = v0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00779379-a14d-4c33-aa88-1a9953eec0ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc0db7-c408-4115-b861-e6be775f46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "noise = 0.0\n",
    "\n",
    "N_u = 100\n",
    "N_f = 10000\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t = data[\"t\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"]).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = Exact[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = Exact[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = Exact[:, -1:]\n",
    "\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "x_u = X_u_train[:, 0:1]\n",
    "t_u = X_u_train[:, 1:2]\n",
    "\n",
    "x_f = X_f_train[:, 0:1]\n",
    "t_f = X_f_train[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606f96c-8361-4a79-b5f0-5227153b126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uu1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72763e82-a78b-42d9-954f-a7e2e7326a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InitialCondition(Dataset):\n",
    "    def __init__(self, x, t, u):\n",
    "        (\n",
    "            self.spatial_domain_sampled,\n",
    "            self.time_domain_sampled,\n",
    "            self.solution_sampled,\n",
    "        ) = self.convert_to_tensor((x, t, u))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_tensor(arrays, requires_grad=False):\n",
    "        return [\n",
    "            torch.tensor(array, dtype=torch.float32, requires_grad=requires_grad)\n",
    "            for array in arrays\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solution_sampled)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            [\n",
    "                self.spatial_domain_sampled[idx, i : i + 1]\n",
    "                for i in range(self.spatial_domain_sampled.shape[1])\n",
    "            ],\n",
    "            self.time_domain_sampled[idx],\n",
    "            self.solution_sampled[idx],\n",
    "        )\n",
    "\n",
    "\n",
    "class CollectionPoints(Dataset):\n",
    "    def __init__(self, x, t):\n",
    "        (self.spatial_domain_sampled, self.time_domain_sampled) = self.convert_to_tensor((x, t))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_tensor(arrays, requires_grad=False):\n",
    "        return [\n",
    "            torch.tensor(array, dtype=torch.float32, requires_grad=requires_grad)\n",
    "            for array in arrays\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_domain_sampled)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            [\n",
    "                self.spatial_domain_sampled[idx, i : i + 1]\n",
    "                for i in range(self.spatial_domain_sampled.shape[1])\n",
    "            ],\n",
    "            self.time_domain_sampled[idx],\n",
    "        )\n",
    "\n",
    "\n",
    "class Boundary(Dataset):\n",
    "    def __init__(self, x1, x2, t1, t2):\n",
    "        (\n",
    "            self.spatial_domain_sampled_1,\n",
    "            self.spatial_domain_sampled_2,\n",
    "            self.time_domain_sampled_1,\n",
    "            self.time_domain_sampled_2,\n",
    "        ) = self.convert_to_tensor((x1, x2, t1, t2))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_tensor(arrays, requires_grad=False):\n",
    "        return [\n",
    "            torch.tensor(array, dtype=torch.float32, requires_grad=requires_grad)\n",
    "            for array in arrays\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_domain_sampled_1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            [\n",
    "                self.spatial_domain_sampled_1[idx, i : i + 1]\n",
    "                for i in range(self.spatial_domain_sampled_1.shape[1])\n",
    "            ],\n",
    "            [\n",
    "                self.spatial_domain_sampled_2[idx, i : i + 1]\n",
    "                for i in range(self.spatial_domain_sampled_2.shape[1])\n",
    "            ],\n",
    "            self.time_domain_sampled_1[idx],\n",
    "            self.time_domain_sampled_2[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472afa22-0d36-49a4-bbb2-f53544f137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = InitialCondition(x_u, t_u, u_train)\n",
    "f = CollectionPoints(x_f, t_f)\n",
    "val = InitialCondition(X_star[:, 0][:, None], X_star[:, 1][:, None], u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f666a8-0675-4187-a912-2b3a9b4d8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch.utilities import move_data_to_device\n",
    "from src.utils.gradient import fwd_gradient, gradient\n",
    "from torchmetrics import MeanMetric, MinMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "\n",
    "class PINNModule(LightningModule):\n",
    "    \"\"\"Example of a `LightningModule` for PDE equations.\n",
    "\n",
    "    A `LightningModule` implements 8 key methods:\n",
    "\n",
    "    ```python\n",
    "    def __init__(self):\n",
    "    # Define initialization code here.\n",
    "\n",
    "    def setup(self, stage):\n",
    "    # Things to setup before each stage, 'fit', 'validate', 'test', 'predict'.\n",
    "    # This hook is called on every process when using DDP.\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # The complete training step.\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "    # The complete validation step.\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "    # The complete test step.\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "    # The complete predict step.\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "    # Define and configure optimizers and LR schedulers.\n",
    "    ```\n",
    "\n",
    "    Docs:\n",
    "        https://lightning.ai/docs/pytorch/latest/common/lightning_module.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: torch.nn.Module,\n",
    "        pde_fn: Callable[[Any, ...], torch.Tensor],\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler = None,\n",
    "        extra_variables: Dict[str, Any] = None,\n",
    "        output_fn: Callable[[Any, ...], torch.Tensor] = None,\n",
    "        runge_kutta=None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a `PINNModule`.\n",
    "\n",
    "        :param net: The model to train.\n",
    "        :param pde_fn: PDE function.\n",
    "        :param optimizer: The optimizer to use for training.\n",
    "        :param scheduler: The learning rate scheduler to use for training.\n",
    "        :param extra_variables: Extra variables should be in a dictionary.\n",
    "        :param output_fn: Output function will apply on the output of the net.\n",
    "        :param runge_kutta: Runge–Kutta method will be used in discrete problems.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False, ignore=[\"net\"])\n",
    "\n",
    "        self.net = net\n",
    "        self.capture_end = False\n",
    "        self.extra_variables = self.fix_extra_variables(extra_variables)\n",
    "        self.output_fn = output_fn\n",
    "        self.pde_fn = pde_fn\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        self.rk = runge_kutta\n",
    "\n",
    "        # for averaging loss across batches\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.val_loss = MeanMetric()\n",
    "        self.val_error = MeanMetric()\n",
    "        self.test_loss = MeanMetric()\n",
    "        self.test_error = MeanMetric()\n",
    "\n",
    "        # for tracking best so far validation accuracy\n",
    "        self.val_loss_best = MinMetric()\n",
    "\n",
    "    def fix_extra_variables(self, extra_variables):\n",
    "        if extra_variables is None:\n",
    "            return None\n",
    "        extra_variables_parameters = {}\n",
    "        for key in extra_variables:\n",
    "            extra_variables_parameters[key] = torch.tensor(\n",
    "                [extra_variables[key]], dtype=torch.float32, requires_grad=True\n",
    "            )\n",
    "        extra_variables_parameters = torch.nn.ParameterDict(extra_variables_parameters)\n",
    "        return extra_variables_parameters\n",
    "\n",
    "    def forward(self, spatial: List[torch.Tensor], time: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Perform a forward pass through the model `self.net`.\n",
    "\n",
    "        :param spatial: List of input spatial tensors.\n",
    "        :param time: Input tensor representing time.\n",
    "        :return: A tensor of solutions.\n",
    "        \"\"\"\n",
    "        return self.net(spatial, time)\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        if self.rk:\n",
    "            self.rk.to(self.device)\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        if self.rk:\n",
    "            self.rk.to(self.device)\n",
    "\n",
    "    def on_train_start(self) -> None:\n",
    "        \"\"\"Lightning hook that is called when training begins.\"\"\"\n",
    "        # by default lightning executes validation step sanity checks before training starts,\n",
    "        # so it's worth to make sure validation metrics don't store results from these checks\n",
    "        self.val_loss.reset()\n",
    "        self.val_loss_best.reset()\n",
    "\n",
    "    def model_step(\n",
    "        self,\n",
    "        batch: Dict[\n",
    "            str,\n",
    "            Union[\n",
    "                Tuple[torch.Tensor, torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]\n",
    "            ],\n",
    "        ],\n",
    "        batch_idx: int = 0,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Perform a single model step on a batch of data.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the\n",
    "        input tensor of different conditions and data.\n",
    "\n",
    "        :return: A tuple containing (in order):\n",
    "            - A tensor of losses.\n",
    "            - A tensor of predictions.\n",
    "        \"\"\"\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for key in batch:\n",
    "            if len(batch[key]) == 2:\n",
    "                x, t = batch[key]\n",
    "            elif len(batch[key]) == 3:\n",
    "                x, t, u = batch[key]\n",
    "            else:\n",
    "                x_ub, x_lb, t_ub, t_lb = batch[key]\n",
    "                if batch_idx == 0:\n",
    "                    t_lb = t_lb.requires_grad_(True)\n",
    "                    t_ub = t_ub.requires_grad_(True)\n",
    "                    x_ub = [x_.requires_grad_(True) for x_ in x_ub]\n",
    "                    x_lb = [x_.requires_grad_(True) for x_ in x_lb]\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                t = t.requires_grad_(True)\n",
    "                x = [x_.requires_grad_(True) for x_ in x]\n",
    "\n",
    "            \"\"\"         \n",
    "            elif key == 'PeriodicBoundaryCondition_1':\n",
    "                if t.size()[0] == 2:\n",
    "                    t = None\n",
    "                u_pred = self.forward(x, t)\n",
    "                mid = u_pred.size()[0]//2\n",
    "                loss = 0.0\n",
    "                for i in range(u_pred.shape[-1]):\n",
    "                    if t is not None:\n",
    "                        u_pred_x = gradient(u_pred[:, i:i+1], x)\n",
    "                    else:\n",
    "                        u_pred_x = fwd_gradient(u_pred[:, i:i+1], x)                    \n",
    "                    loss = loss + torch.sum(torch.square(u_pred_x[:mid]-u_pred_x[mid:]))\n",
    "                loss = loss + torch.sum(torch.square(u_pred[:mid]-u_pred[mid:]))\n",
    "            \"\"\"\n",
    "            if key == \"PeriodicBoundaryCondition_0\":\n",
    "                if t.size()[0] == 2:\n",
    "                    t = None\n",
    "                u_pred = self.forward(x, t)\n",
    "                mid = u_pred.size()[0] // 2\n",
    "                loss = torch.sum(torch.square(u_pred[:mid] - u_pred[mid:]))\n",
    "\n",
    "            elif key == \"Boundary\":\n",
    "                if t.size()[0] == 2:\n",
    "                    t = None\n",
    "                u_pred_ub = self.forward(x_ub, t_ub)\n",
    "                u_pred_lb = self.forward(x_lb, t_lb)\n",
    "                loss = 0.0\n",
    "                for i in range(u_pred_lb.shape[-1]):\n",
    "                    if t is not None:\n",
    "                        u_pred_x_ub = gradient(u_pred_ub[:, i : i + 1], x_ub)\n",
    "                        u_pred_x_lb = gradient(u_pred_lb[:, i : i + 1], x_lb)\n",
    "                    else:\n",
    "                        u_pred_x_ub = fwd_gradient(u_pred_ub[:, i : i + 1], x_ub)\n",
    "                        u_pred_x_lb = fwd_gradient(u_pred_lb[:, i : i + 1], x_lb)\n",
    "                    loss = loss + torch.mean(torch.square(u_pred_x_ub - u_pred_x_lb))\n",
    "                    loss = loss + torch.mean(\n",
    "                        torch.square(u_pred_ub[:, i : i + 1] - u_pred_lb[:, i : i + 1])\n",
    "                    )\n",
    "            elif key == \"MeshSampler_alpha\":\n",
    "                z = self.forward(x, None)\n",
    "                f = self.pde_fn(z, *x, self.extra_variables)\n",
    "                u_pred = z - self.rk[\"dt\"] * torch.matmul(f, self.rk[\"alpha\"])\n",
    "                loss = torch.sum(torch.square(u_pred - u))\n",
    "\n",
    "            elif key == \"MeshSampler_beta\":\n",
    "                z = self.forward(x, None)\n",
    "                f = self.pde_fn(z, *x, self.extra_variables)\n",
    "                u_pred = z + self.rk[\"dt\"] * torch.matmul(f, (self.rk[\"beta\"] - self.rk[\"alpha\"]))\n",
    "                loss = torch.sum(torch.square(u_pred - u))\n",
    "\n",
    "            elif key == \"MeshSampler_weights\":\n",
    "                z = self.forward(x, None)\n",
    "                f = self.pde_fn(z, *x, self.extra_variables)\n",
    "                u_pred = z - self.rk[\"dt\"] * torch.matmul(f, self.rk[\"weights\"])\n",
    "                loss = torch.sum(torch.square(u_pred - u))\n",
    "\n",
    "            elif key == \"MeshSampler_use_data\":\n",
    "                if self.output_fn:\n",
    "                    u_pred = self.forward(x, t)\n",
    "                    u_pred_new = self.output_fn(u_pred, *x, t)\n",
    "                    f = self.pde_fn(u_pred, *x, t, self.extra_variables)\n",
    "                    loss = torch.sum(torch.square(u_pred_new - u)) + torch.sum(torch.square(f))\n",
    "                else:\n",
    "                    u_pred = self.forward(x, t)\n",
    "                    f = self.pde_fn(u_pred, *x, t, self.extra_variables)\n",
    "                    loss = torch.sum(torch.square(u_pred - u)) + torch.sum(torch.square(f))\n",
    "\n",
    "            elif key.startswith(\"CollectionPoints\"):\n",
    "                u_pred = self.forward(x, t)\n",
    "                f = self.pde_fn(u_pred, *x, t, self.extra_variables)\n",
    "                loss = torch.mean(torch.square(f))\n",
    "\n",
    "            else:\n",
    "                u_pred = self.forward(x, t)\n",
    "                print(u_pred.shape, u.shape)\n",
    "                loss = torch.mean(torch.square(u_pred - u))\n",
    "\n",
    "        total_loss = total_loss + loss\n",
    "        return total_loss, u_pred\n",
    "\n",
    "    def capture_graph(self, batch):\n",
    "        self.opt = self.optimizers()\n",
    "\n",
    "        self.new_batch = batch\n",
    "        self.batch_idx = 0\n",
    "\n",
    "        s = torch.cuda.Stream()\n",
    "        s.wait_stream(torch.cuda.current_stream())\n",
    "        with torch.cuda.stream(s):\n",
    "            for i in range(11):\n",
    "                self.opt.zero_grad(set_to_none=True)\n",
    "                loss, pred = self.model_step(self.new_batch, self.batch_idx)\n",
    "                self.manual_backward(loss)\n",
    "                self.opt.step()\n",
    "\n",
    "        torch.cuda.current_stream().wait_stream(s)\n",
    "        g = torch.cuda.CUDAGraph()\n",
    "        with torch.cuda.graph(g):\n",
    "            self.opt.zero_grad(set_to_none=True)\n",
    "            self.static_loss, self.static_pred = self.model_step(self.new_batch, self.batch_idx)\n",
    "            self.manual_backward(self.static_loss)\n",
    "            self.opt.step()\n",
    "\n",
    "        self.batch_idx = 1\n",
    "        self.capture_end = True\n",
    "\n",
    "        return g\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: Dict[\n",
    "            str,\n",
    "            Union[\n",
    "                Tuple[torch.Tensor, torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]\n",
    "            ],\n",
    "        ],\n",
    "        batch_idx: int,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Perform a single training step on a batch of data from the training set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        :return: A tensor of losses between model predictions and targets.\n",
    "        \"\"\"\n",
    "\n",
    "        if batch_idx == 0 and not self.capture_end:\n",
    "            self.g = self.capture_graph(batch)\n",
    "        else:\n",
    "            self.g.replay()\n",
    "\n",
    "        # update and log metrics\n",
    "        self.train_loss(self.static_loss)\n",
    "        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.current_epoch > 20000 and self.current_epoch%20 == 0:\n",
    "            self.scheduler.step(self.static_loss)\n",
    "    \n",
    "            for param_group in self.optimizers().param_groups:\n",
    "                lr = param_group['lr']\n",
    "    \n",
    "            self.log(\"lr\", lr, prog_bar=True, sync_dist=False)\n",
    "        \"\"\"\n",
    "        # for param_group in self.optimizers().param_groups:\n",
    "        #    lr = param_group['lr']\n",
    "\n",
    "        # self.log(\"lr_rate\", lr, prog_bar=True, sync_dist=False)\n",
    "        return self.static_loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.extra_variables:\n",
    "            for key in self.extra_variables:\n",
    "                self.log(key, self.extra_variables[key], prog_bar=True)\n",
    "\n",
    "    def make_requires_grad_(self, batch):\n",
    "        x, t, u = batch\n",
    "        if self.rk:\n",
    "            t = None\n",
    "        else:\n",
    "            t = t.requires_grad_(True)\n",
    "        x = [x_.requires_grad_(True) for x_ in x]\n",
    "        return (x, t, u)\n",
    "\n",
    "    def eval_step(self, batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]) -> None:\n",
    "        u_pred = self.forward(x, t)\n",
    "        if self.output_fn:\n",
    "            u_pred = self.output_fn(u_pred, *x, t)\n",
    "\n",
    "        if self.rk:\n",
    "            loss = torch.sum(torch.square(u_pred[:, -1:] - u))\n",
    "            error_list = [torch.norm(u_pred[:, -1:] - u, p=2) / torch.norm(u, p=2)]\n",
    "        else:\n",
    "            loss = torch.sum(torch.square(u_pred - u))\n",
    "            error_list = [\n",
    "                torch.norm(u_pred[:, i] - u[:, i], p=2) / torch.norm(u[:, i], p=2)\n",
    "                for i in range(u_pred.shape[-1])\n",
    "            ]\n",
    "\n",
    "        return loss, error_list, u_pred\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> None:\n",
    "        \"\"\"Perform a single validation step on a batch of data from the validation set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, error_list, pred = self.eval_step(batch)\n",
    "        self.val_loss(loss)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, sync_dist=False)\n",
    "        for i, error in enumerate(error_list):\n",
    "            self.val_error(error)\n",
    "            self.log(f\"val/error_{i}\", error, prog_bar=True, sync_dist=False)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        \"Lightning hook that is called when a validation epoch ends.\"\n",
    "        loss = self.val_loss.compute()\n",
    "        error = self.val_loss.compute()\n",
    "        self.val_loss_best(loss)\n",
    "        self.log(\"val/loss_best\", self.val_loss_best.compute(), sync_dist=True, prog_bar=True)\n",
    "        self.val_loss.reset()\n",
    "\n",
    "    def test_step(\n",
    "        self,\n",
    "        batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "        batch_idx: int,\n",
    "        set_grad_enabled=True,\n",
    "    ) -> None:\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, error, pred = self.eval_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.test_loss(loss)\n",
    "        self.test_error(error)\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/error\", error, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def prediction_step(\n",
    "        self,\n",
    "        batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "        batch_idx: int,\n",
    "        set_grad_enabled=True,\n",
    "    ) -> None:\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, error, pred = self.eval_step(batch)\n",
    "        return pred\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        \"\"\"Lightning hook that is called when a test epoch ends.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self) -> Dict[str, Any]:\n",
    "        \"\"\"Configures optimizers and learning-rate schedulers to be used for training.\n",
    "\n",
    "        Normally you'd need one, but in the case of GANs or similar you might need multiple.\n",
    "\n",
    "        Examples:\n",
    "            https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers\n",
    "\n",
    "        :return: A dict containing the configured optimizers and learning-rate schedulers to be used for training.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), capturable=True)\n",
    "\n",
    "        return {\"optimizer\": optimizer}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _ = PINNModule(None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d79e8-ece4-4053-ae96-6b5e52ae4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from src.data.pinn_datamodule import PINNDataModule\n",
    "from src.models.net.neural_net import FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da770c-e8f9-436e-b664-a1ddbd612279",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = PINNDataModule(train_datasets=[ic, f], val_dataset=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160700e-9ec7-4a1b-8c17-fea716da2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FCN(layers=[2, 20, 20, 20, 20, 20, 20, 20, 20, 1], lb=lb, ub=ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844d66a-dc97-4db5-ad36-beb7aa53fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd, ones_like\n",
    "\n",
    "\n",
    "def gradient(dy, dx, ones_like_tensor=None, create_graph=True):\n",
    "    if ones_like_tensor is None:\n",
    "        ones_like_tensor = ones_like(dy, requires_grad=False)\n",
    "    dy_dx = autograd.grad(\n",
    "        dy,\n",
    "        dx,\n",
    "        grad_outputs=ones_like_tensor,\n",
    "        create_graph=create_graph,\n",
    "        retain_graph=True,\n",
    "        allow_unused=False,\n",
    "    )\n",
    "    if len(dy_dx) == 1:\n",
    "        dy_dx = dy_dx[0]\n",
    "    return dy_dx\n",
    "\n",
    "\n",
    "def pde_fn(u, x, t, extra_variables=None):\n",
    "    u_x = gradient(u, x)\n",
    "    u_t = gradient(u, t)\n",
    "    u_xx = gradient(u_x, x)[0]\n",
    "    return u_t + u * u_x - (0.01 / np.pi) * u_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1bebc4-7b08-4134-aeb4-6dca4f2d332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=50000, devices=[0], check_val_every_n_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0d73e-f5ec-47ef-a183-0df608b4b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINNModule(net=net, pde_fn=pde_fn, optimizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d149d-01de-4055-a8f5-7bebe8e0d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02594f-6894-4477-a115-e298dfd5f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = model([val.spatial_domain_sampled], val.time_domain_sampled).detach().numpy()\n",
    "from pyDOE import lhs\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "nu = 0.01 / np.pi\n",
    "noise = 0.0\n",
    "\n",
    "N_u = 100\n",
    "N_f = 10000\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t = data[\"t\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"]).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = Exact[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = Exact[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = Exact[:, -1:]\n",
    "\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method=\"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f6ee3-4a98-46ef-b303-21398b3a27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "exact_u = np.real(data[\"usol\"]).astype(\"float32\")\n",
    "\n",
    "\n",
    "def figsize(scale, nplots=1):\n",
    "    fig_width_pt = 390.0  # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0 / 72.27  # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0) - 1.0) / 2.0  # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt * inches_per_pt * scale  # width in inches\n",
    "    fig_height = nplots * fig_width * golden_mean  # height in inches\n",
    "    fig_size = [fig_width, fig_height]\n",
    "    return fig_size\n",
    "\n",
    "\n",
    "def newfig(width, nplots=1):\n",
    "    fig = plt.figure(figsize=figsize(width, nplots))\n",
    "    ax = fig.add_subplot(111)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "######################################################################\n",
    "############################# Plotting ###############################\n",
    "######################################################################\n",
    "\n",
    "fig, ax = newfig(1.0, 1.1)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "####### Row 1: u(t,x) slices ##################\n",
    "gs1 = gridspec.GridSpec(1, 3)\n",
    "gs1.update(top=1 - 1 / 3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 0])\n",
    "ax.plot(x, exact_u[:, 25], \"b-\", linewidth=2, label=\"Exact\")\n",
    "ax.plot(x, U_pred[25, :], \"r--\", linewidth=2, label=\"Prediction\")\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$u(t,x)$\")\n",
    "ax.set_title(\"$t = 0.25$\", fontsize=10)\n",
    "ax.axis(\"square\")\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1])\n",
    "ax.plot(x, exact_u[:, 50], \"b-\", linewidth=2, label=\"Exact\")\n",
    "ax.plot(x, U_pred[50, :], \"r--\", linewidth=2, label=\"Prediction\")\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$u(t,x)$\")\n",
    "ax.axis(\"square\")\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "ax.set_title(\"$t = 0.50$\", fontsize=10)\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2])\n",
    "ax.plot(x, exact_u[:, 75], \"b-\", linewidth=2, label=\"Exact\")\n",
    "ax.plot(x, U_pred[50, :], \"r--\", linewidth=2, label=\"Prediction\")\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$u(t,x)$\")\n",
    "ax.axis(\"square\")\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "ax.set_title(\"$t = 0.75$\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23675a-e27c-4f6c-aa31-e7292d7bd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadb788-a9c7-4a25-b828-0d3f04d7f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = model.u_pred.cpu().detach()\n",
    "u_star = model.u_star.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7bd5c-75ca-4097-94a0-de4a5b552fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.square(u_pred[:, 0:1] - u_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5426f42-06f8-4a20-8bdb-f62af7ce3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = model.u_pred.cpu().detach().numpy()\n",
    "u_star = model.u_star.cpu().numpy()\n",
    "np.sum(np.square(u_pred[:, 0:1] - u_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59830cb9-cd7d-448a-af80-5434301da194",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = np.array(\n",
    "    [\n",
    "        [2.7091e-01, 3.9882e-03],\n",
    "        [2.7687e-01, 1.1623e-02],\n",
    "        [2.6562e-01, -4.3583e-03],\n",
    "        [2.6574e-01, -3.9669e-03],\n",
    "        [2.6638e-01, -2.6910e-03],\n",
    "        [2.6875e-01, 2.9218e-04],\n",
    "        [2.6829e-01, -6.7141e-04],\n",
    "        [2.6760e-01, -1.9919e-03],\n",
    "        [2.6845e-01, -3.5939e-04],\n",
    "        [2.6562e-01, -4.4337e-03],\n",
    "        [2.7271e-01, 6.3726e-03],\n",
    "        [2.7899e-01, 1.4200e-02],\n",
    "        [2.6860e-01, -3.8063e-05],\n",
    "        [2.6563e-01, -4.4611e-03],\n",
    "        [2.6597e-01, -4.3149e-03],\n",
    "        [2.6605e-01, -4.2324e-03],\n",
    "        [2.6762e-01, -6.8513e-04],\n",
    "        [2.6591e-01, -3.5690e-03],\n",
    "        [2.6769e-01, -1.8177e-03],\n",
    "        [2.6585e-01, -4.4194e-03],\n",
    "        [2.6720e-01, -1.3304e-03],\n",
    "        [2.6769e-01, -5.7203e-04],\n",
    "        [2.6594e-01, -3.5116e-03],\n",
    "        [2.7115e-01, 4.3136e-03],\n",
    "        [2.7010e-01, 2.8917e-03],\n",
    "        [2.6860e-01, 7.7208e-04],\n",
    "        [2.6571e-01, -4.0494e-03],\n",
    "        [2.7827e-01, 1.3326e-02],\n",
    "        [2.7021e-01, 3.0445e-03],\n",
    "        [2.6579e-01, -3.8305e-03],\n",
    "        [2.6563e-01, -4.3102e-03],\n",
    "        [2.6819e-01, -8.7406e-04],\n",
    "        [2.7791e-01, 1.2895e-02],\n",
    "        [2.6684e-01, -1.9184e-03],\n",
    "        [2.6707e-01, -1.5328e-03],\n",
    "        [2.6824e-01, -7.7320e-04],\n",
    "        [2.6878e-01, 1.0360e-03],\n",
    "        [2.6611e-01, -4.1694e-03],\n",
    "        [2.6989e-01, 2.5907e-03],\n",
    "        [2.6649e-01, -3.7087e-03],\n",
    "        [2.6814e-01, -9.7357e-04],\n",
    "        [2.6733e-01, -1.1218e-03],\n",
    "        [2.6562e-01, -4.4482e-03],\n",
    "        [2.6825e-01, 2.6217e-04],\n",
    "        [2.7431e-01, 8.4140e-03],\n",
    "        [2.6592e-01, -4.3617e-03],\n",
    "        [2.6627e-01, -3.9835e-03],\n",
    "        [2.6789e-01, -1.4544e-03],\n",
    "        [2.7809e-01, 1.3110e-02],\n",
    "        [2.6562e-01, -4.3797e-03],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166e8b2-7537-4756-bde7-d1681dd1eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_star = np.array(\n",
    "    [\n",
    "        [0.2302],\n",
    "        [0.0466],\n",
    "        [1.6998],\n",
    "        [1.9863],\n",
    "        [1.5904],\n",
    "        [0.0612],\n",
    "        [0.0870],\n",
    "        [0.1501],\n",
    "        [0.0774],\n",
    "        [1.5524],\n",
    "        [0.1336],\n",
    "        [0.0291],\n",
    "        [0.0688],\n",
    "        [1.4752],\n",
    "        [0.7207],\n",
    "        [0.6455],\n",
    "        [0.8323],\n",
    "        [1.9625],\n",
    "        [0.1389],\n",
    "        [0.8623],\n",
    "        [1.0244],\n",
    "        [0.8032],\n",
    "        [1.9463],\n",
    "        [0.2130],\n",
    "        [0.3019],\n",
    "        [0.5356],\n",
    "        [1.9625],\n",
    "        [0.0341],\n",
    "        [0.2905],\n",
    "        [2.0000],\n",
    "        [1.7672],\n",
    "        [0.0940],\n",
    "        [0.0368],\n",
    "        [1.2425],\n",
    "        [1.0945],\n",
    "        [0.0904],\n",
    "        [0.4967],\n",
    "        [0.5993],\n",
    "        [0.3261],\n",
    "        [0.3952],\n",
    "        [0.0978],\n",
    "        [0.9571],\n",
    "        [1.5140],\n",
    "        [0.6220],\n",
    "        [0.0870],\n",
    "        [0.7748],\n",
    "        [0.4967],\n",
    "        [0.1188],\n",
    "        [0.0354],\n",
    "        [1.6642],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2728dd1-434b-41d7-a836-0ee87532171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(tf.square())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1cdd5-b041-4ef9-b618-15efe0e8dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = model.u_pred.cpu().detach().numpy()\n",
    "u_star = model.u_star.cpu().numpy()\n",
    "np.sum(np.square(u_pred[:, 0:1] - u_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806ff9a-e3de-4a12-9cf6-3ff772a36f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    mesh.solution_mesh[:, :, 0],\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    extent=[mesh.lb[1], mesh.ub[1], mesh.lb[0], mesh.ub[0]],\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab388831-fa10-400a-a3a1-ac3ae9f11de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    mesh.solution_mesh[:, :, 0],\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    extent=[mesh.lb[1], mesh.ub[1], mesh.lb[0], mesh.ub[0]],\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391409f-ce07-4a8c-8fd5-48af37b446f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t = data[\"t\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"]).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb5efe-8851-4173-ae0c-7dc12d9a41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "\n",
    "layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 2]\n",
    "\n",
    "# Load Data\n",
    "data = scipy.io.loadmat(\"data/cylinder_nektar_wake.mat\")\n",
    "\n",
    "U_star = data[\"U_star\"]  # N x 2 x T\n",
    "P_star = data[\"p_star\"]  # N x T\n",
    "t_star = data[\"t\"]  # T x 1\n",
    "X_star = data[\"X_star\"]  # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "# Rearrange Data\n",
    "XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "UU = U_star[:, 0, :]  # N x T\n",
    "VV = U_star[:, 1, :]  # N x T\n",
    "PP = P_star  # N x T\n",
    "\n",
    "x = XX.flatten()[:, None]  # NT x 1\n",
    "y = YY.flatten()[:, None]  # NT x 1\n",
    "t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "u = UU.flatten()[:, None]  # NT x 1\n",
    "v = VV.flatten()[:, None]  # NT x 1\n",
    "p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "######################################################################\n",
    "######################## Noiseles Data ###############################\n",
    "######################################################################\n",
    "# Training Data\n",
    "idx = np.random.choice(N * T, N_train, replace=False)\n",
    "x_train = x[idx, :]\n",
    "y_train = y[idx, :]\n",
    "t_train = t[idx, :]\n",
    "u_train = u[idx, :]\n",
    "v_train = v[idx, :]\n",
    "\n",
    "# Test Data\n",
    "snap = np.array([100])\n",
    "x_star = X_star[:, 0:1]\n",
    "y_star = X_star[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d4f1e-b16b-4acd-91da-8b1bf8f1a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_star.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e305f3b-42cf-45e9-8d01-a24c9a73d90b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NavierStokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a967c-a917-443a-bc20-5871090cd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnstorch.data import (\n",
    "    InitialCondition,\n",
    "    Interval,\n",
    "    Mesh,\n",
    "    MeshSampler,\n",
    "    PeriodicBoundaryCondition,\n",
    "    PINNDataModule,\n",
    "    PointCloud,\n",
    "    PointCloudData,\n",
    "    Rectangle,\n",
    "    TimeDomain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f7d10-3c48-46a4-bccc-dda319ad27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnstorch.utils import load_data\n",
    "\n",
    "\n",
    "def read_data_fn(root_path):\n",
    "    data = load_data(root_path, \"cylinder_nektar_wake.mat\")\n",
    "    U_star = data[\"U_star\"]  # N x 2 x T\n",
    "    exact_u = U_star[:, 0, :]\n",
    "    exact_v = U_star[:, 1, :]\n",
    "    p_star = data[\"p_star\"]  # N x 2 x T\n",
    "    return PointCloudData(\n",
    "        spatial=[data[\"X_star\"][:, 0:1], data[\"X_star\"][:, 1:2]],  # N x 1  # N x 1\n",
    "        time=[data[\"t\"]],  # T x 1\n",
    "        solution={\"u\": exact_u, \"v\": exact_v, \"p\": p_star},  # N x T  # N x T\n",
    "    )\n",
    "\n",
    "\n",
    "def read_data_fn_2(root_path):\n",
    "    data = load_data(root_path, \"cylinder_nektar_wake.mat\")\n",
    "    U_star = data[\"U_star\"]  # N x 2 x T\n",
    "    exact_u = U_star[:, 0, :]\n",
    "    exact_v = U_star[:, 1, :]\n",
    "    p_star = data[\"p_star\"]  # N x 2 x T\n",
    "    return {\"u\": exact_u, \"v\": exact_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16079a18-55f1-4731-9646-64f03f085794",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PointCloud(\"data\", read_data_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549c6ac-6eca-454a-98c6-b5c376e4d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TimeDomain([0, 19.9], 200)\n",
    "sd = Rectangle([1, 8], [-2, 2], [100, 50])\n",
    "mesh = Mesh(time_domain=td, spatial_domain=sd, root_dir=\"data\", read_data_fn=read_data_fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa62e5-0472-44d2-82dd-96fed5085a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.time_domain_mesh.shape, pc.time_domain_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b0ff0-0585-4290-8bb5-9fd08d35e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.solution[\"v\"].shape, pc.solution[\"v\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c43b6a-ba0a-409b-beb1-df677fb566ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = pc.on_lower_boundary([\"v\", \"u\"])\n",
    "xx, tt, uu = mesh.on_lower_boundary([\"v\", \"u\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bf2fc-f112-4fee-90f0-001aa3241886",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6817c-71b7-49e1-8b53-a309aceaf6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.on_lower_boundary([\"v\", \"u\"]), mesh.on_lower_boundary([\"v\", \"u\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d4edb-bcc4-429f-9fbc-f3b11114bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"data\", \"cylinder_nektar_wake.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a4513-53c7-4f73-803a-4e8398503913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"t\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1037fbd-f30a-4821-8c44-abccac8e6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"U_star\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc24ba1-25b9-4dcf-9c1b-9ad79e945f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TimeDomain([0, 19.9], 200)\n",
    "sd = Rectangle([1, 8], [-2, 2], [100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ae9cb-19a8-448a-ae8c-3a2dbcafdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(first_arg, *args, **kwargs):\n",
    "    print(\"First argument:\", first_arg)\n",
    "    print(\"Positional arguments:\", args)\n",
    "    print(\"Keyword arguments:\", kwargs)\n",
    "    print(\"Keyword arguments:\", kwargs[\"a\"])\n",
    "\n",
    "\n",
    "my_function(\"hello\", 1, 2, 3, a=10, b=20)\n",
    "# Output:\n",
    "# First argument: hello\n",
    "# Positional arguments: (1, 2, 3)\n",
    "# Keyword arguments: {'a': 10, 'b': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a743c8-7778-48f4-9066-5c78d9e216ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "my_variable = [1, 2, 3, 4, 5]\n",
    "size = sys.getsizeof(my_variable)\n",
    "\n",
    "print(f\"Size of my_variable: {size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03948bc6-eb3b-44b7-9cc3-fe3d2d7a5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = Rectangle([1, 8], [-2, 2], [100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b136a-eafc-497e-ae5c-96932064d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(root_dir=\"data\", time_domain=td, spatial_domain=sd, read_data_fn=read_data_fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f179236-d9c5-4059-b7b7-05348d8f5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = mesh.flatten_mesh([\"u\", \"v\"])\n",
    "xx, tt, uu = pc.flatten_mesh([\"u\", \"v\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda589a1-09ca-488b-9e72-89dd81cb39d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(uu[\"u\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35b522-465a-44c8-9f1b-94be36e687ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "[4] + 10 * [5 * 50] + [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec45b47-9dac-4b03-bce2-cd7c04fc784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uu[\"u\"] - u[\"u\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3a604-0e07-48c5-b32d-69f988f59604",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = PeriodicBoundaryCondition(mesh, num_sample=50, derivative_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5192b-8981-41f1-8a38-d83eaab95bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = InitialCondition(mesh, num_sample=50, solution=\"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b5c37-4cdc-4f74-83a3-5e2e18c64fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([50, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee6558-69b9-4765-99ed-3f3bc657cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(50, 30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d91cc-f8e4-4658-aef4-deb028caa9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb77674-1543-44a7-857c-c390c2732897",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabefbb2-f603-499d-adf4-6b2904fff1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fe246-6d6d-4d47-9d07-7b08f694cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MeshSampler(mesh, num_sample=20000, use_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca68d2-3e55-4ba8-bd64-892b8ab591ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = MeshSampler(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e2f67-9e0b-48c3-8d94-81e3981e7c2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Burgurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8409c-6a0b-4bcf-8826-bfb5d5df767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import load_data\n",
    "\n",
    "\n",
    "def read_data_fn(root_path):\n",
    "    data = load_data(root_path, \"burgers_shock.mat\")\n",
    "    exact_u = np.real(data[\"usol\"]).astype(\"float32\")\n",
    "    return data, [exact_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc2aa5-f78a-461f-98f5-21de9d8a654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, [exact_u] = read_data_fn(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a74e4-f1d7-47b4-8ecb-44ab14739377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.domains.spatial import Cube, Interval, Rectangle\n",
    "from src.data.domains.time import TimeDomain\n",
    "from src.data.mesh.mesh import Mesh\n",
    "from src.data.pinn_datamodule import PINNDataModule\n",
    "from src.data.sampler.boundary_condition import DirichletBoundaryCondition\n",
    "from src.data.sampler.initial_condition import InitialCondition\n",
    "from src.data.sampler.mesh_sampler import MeshSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a58ed7-214d-42d9-9b73-b05c45fc346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TimeDomain([0, 0.99], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b837226-a8e7-4e76-96e6-9dec6c3aff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = Interval([-1, 1], [256, 1])\n",
    "# sd = Rectangle([-1, 1], [3, 12], [256, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a23f9d-d835-4133-8b11-8650f6aa0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(root_dir=\"data\", time_domain=td, spatial_domain=sd, read_data_fn=read_data_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee2a58-4fb1-4db0-89aa-1d38f73139f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DirichletBoundaryCondition(mesh, idx_t=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e82e80-3eec-4caa-a5ae-c7b064037c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = InitialCondition(mesh, num_sample=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036128c6-ec03-4df2-b559-12cee3151b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = ic[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1230d4-c871-44d7-90ae-beccd334e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNDataLoader:\n",
    "    \"\"\"Custom DataLoader for the PINN datasets.\n",
    "\n",
    "    A `PINNDataLoader` implements 3 key methods:\n",
    "\n",
    "    ```python\n",
    "        def  __iter__(self):\n",
    "        #\n",
    "\n",
    "        def __next__(self):\n",
    "        #\n",
    "    ```\n",
    "\n",
    "    This allows you to have a fast dataloader.\n",
    "\n",
    "    Read the docs:\n",
    "        https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size=None, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = list(range(len(self.dataset)))\n",
    "        self.current_index = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            torch.random.manual_seed(42)\n",
    "            torch.random.shuffle(self.indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        batch_indices = self.indices[self.current_index : self.current_index + self.batch_size]\n",
    "        batch = self.dataset[batch_indices]\n",
    "        self.current_index += self.batch_size\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84378c2a-c5e3-4134-ad21-ec21c44c772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = PINNDataLoader(ic, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e1d68-f2e3-4866-83a3-ad09fedbf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemSolver:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def solve(self, inputs, targets):\n",
    "        # Solving logic here\n",
    "        pass\n",
    "\n",
    "\n",
    "# Create instances of the ProblemSolver class\n",
    "solver1 = ProblemSolver(name=\"Solver1\")\n",
    "solver2 = ProblemSolver(name=\"Solver2\")\n",
    "\n",
    "# Create a dictionary with class methods as keys\n",
    "solver_dict = {solver1.solve: \"Solver 1 data\", solver2.solve: \"Solver 2 data\"}\n",
    "\n",
    "# Use the class methods as keys to retrieve data\n",
    "result1 = solver_dict[solver1.solve]\n",
    "result2 = solver_dict[solver2.solve]\n",
    "\n",
    "print(result1)  # Output: 'Solver 1 data'\n",
    "print(result2)  # Output: 'Solver 2 data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9ab2e-e371-4bb4-acca-0b8af968b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in solver_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825b2dc-f3bb-4c04-b8df-0b6eb849c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MeshSampler(mesh, num_sample=10000, use_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7a765-3f9f-4b7d-b2f7-02341eb584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = MeshSampler(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f66f91-1956-49bb-a1ba-51421e4b6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = val[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ff1dd-8d03-4f38-9c90-b9e3ec7907f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].min(), x[0].max(), t.min(), t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf72fc1-d6ff-42bc-b4b3-96c02f21e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "noise = 0.0\n",
    "\n",
    "N_u = 100\n",
    "N_f = 10000\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t = data[\"t\"].flatten()[:, None]\n",
    "x = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"]).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = Exact[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = Exact[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = Exact[:, -1:]\n",
    "\n",
    "X_u_train = np.vstack([xx3, xx2])\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu3, uu2])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "X_u_train_ = X_u_train[idx, :]\n",
    "u_train_ = u_train[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259b07e-a5ac-4c3e-8435-4ab556aeb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e955f-f880-464d-9675-8613ea506abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star.shape, u.shape, u_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ddd2e-5c67-429c-84ce-bdf28d5a2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(u - u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7b50a-d978-46af-9fcc-a0951b407b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_u - np.array(u.reshape(exact_u.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040beabc-89cd-4475-9c43-309e7a9214ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.time_domain_mesh.min(2), mesh.spatial_domain_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04958479-d739-4f19-b0c5-9f38d8c03d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521eea8-04d6-48d3-82fa-e5eb1dd2adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = f[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f4b38-a2b9-484c-b9fa-c9bb984f2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.min(), t.max(), x[0].min(), x[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dceb7ea-e6ba-4dbd-9688-e468ad418d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train[db.idx] - u.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4845395-493a-4caf-8843-c61f3f39b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = db[:]\n",
    "xxx = np.hstack((x[0], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ac63e-abf7-45e0-97ee-78b29a891a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star[1203], u_star[1203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de989b78-8aba-4117-9efc-f92c12b387f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][x[0] == 0.40392157], t[x[0] == 0.40392157], u[x[0] == 0.40392157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55684e-e660-4cf5-88db-42b5e32b9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a31ecc-81e7-4f6c-88ad-b5ec8a03e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "t - X_u_train[100:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb389d65-dd8e-4e59-81a6-c858295e2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_train[100:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621ac12-cbee-418a-a846-9cce97fb170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.hstack((x[0], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8695ce6-9b70-42d2-9d4f-55f3dc55e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uu1, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00895ac9-fdc4-4bd8-b392-f35bb84ee5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54bcd7-b4fb-4808-a145-2a3390c88259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(root_path, 'burgers_shock.mat')\n",
    "    exact_u = np.real(data['usol']).astype('float32')\n",
    "    return data, [exact_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200672ab-0ca3-48de-b683-2cc0006bcc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59421b10-1aa1-455f-80d1-0200bb17bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-5.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8066ba-2ad6-43b2-b311-9ac6e1429c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 80\n",
    "\n",
    "N0 = 199\n",
    "N1 = 201\n",
    "\n",
    "data = scipy.io.loadmat(\"data/burgers_shock.mat\")\n",
    "\n",
    "t_star = data[\"t\"].flatten()[:, None]\n",
    "x_star = data[\"x\"].flatten()[:, None]\n",
    "Exact = np.real(data[\"usol\"])\n",
    "\n",
    "idx_t = 10\n",
    "\n",
    "######################################################################\n",
    "######################## Noiseles Data ###############################\n",
    "######################################################################\n",
    "noise = 0.0\n",
    "\n",
    "idx_x = np.random.choice(Exact.shape[0], N0, replace=False)\n",
    "x0 = x_star[idx_x, :]\n",
    "u0 = Exact[idx_x, idx_t][:, None]\n",
    "u0 = u0 + noise * np.std(u0) * np.random.randn(u0.shape[0], u0.shape[1])\n",
    "\n",
    "idx_x = np.random.choice(Exact.shape[0], N1, replace=False)\n",
    "x1 = x_star[idx_x, :]\n",
    "u1 = Exact[idx_x, idx_t + skip][:, None]\n",
    "u1 = u1 + noise * np.std(u1) * np.random.randn(u1.shape[0], u1.shape[1])\n",
    "\n",
    "dt = (t_star[idx_t + skip] - t_star[idx_t]).item()\n",
    "q = int(np.ceil(0.5 * np.log(np.finfo(float).eps) / np.log(dt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1cce2-d89d-4b16-8cd4-ba1c7200fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c325b-9cbd-48c5-9537-94bffe140ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "np.exp(-5.503359317779541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81231afd-3b7e-4ab8-b999-7a69588c2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.004073065708350454 - 0.003183098861837907) / 0.003183098861837907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5c0be-6918-4c35-b551-57dc4d3face4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [4] + 10 * [5 * 50] + [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f455cc-d334-4836-aaa3-f7aafe04fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1793d-6426-4b09-b3c6-f982b6ee425d",
   "metadata": {},
   "source": [
    "### Aneurysm 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774a3bc-aa07-46cf-8272-68ccb2bc93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinnstorch\n",
    "from pinnstorch.data import (\n",
    "    InitialCondition,\n",
    "    Interval,\n",
    "    Mesh,\n",
    "    MeshSampler,\n",
    "    PeriodicBoundaryCondition,\n",
    "    PINNDataModule,\n",
    "    PointCloud,\n",
    "    PointCloudData,\n",
    "    Rectangle,\n",
    "    TimeDomain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9338b8-0b90-4c1e-9a1d-9a67b6d2793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_fn(root_path):\n",
    "    data = pinnstorch.utils.load_data(root_path, \"Aneurysm3D.mat\")\n",
    "\n",
    "    t_star = data[\"t_star\"]  # T x 1\n",
    "    x_star = data[\"x_star\"]  # N x 1\n",
    "    y_star = data[\"y_star\"]  # N x 1\n",
    "    z_star = data[\"z_star\"]  # N x 1\n",
    "\n",
    "    U_star = data[\"U_star\"]  # N x T\n",
    "    V_star = data[\"V_star\"]  # N x T\n",
    "    W_star = data[\"W_star\"]  # N x T\n",
    "    P_star = data[\"P_star\"]  # N x T\n",
    "    C_star = data[\"C_star\"]  # N x T\n",
    "\n",
    "    return pinnstorch.data.PointCloudData(\n",
    "        spatial=[x_star, y_star, z_star],\n",
    "        time=[t_star],\n",
    "        solution={\"u\": U_star, \"v\": V_star, \"w\": W_star, \"p\": P_star, \"c\": C_star},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23bdd5-1462-4bb8-97e9-82721708d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PointCloud(\"data\", read_data_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad4997-d258-4e4b-a9e6-7df919be2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, u = pc.flatten_mesh([\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5afac9-989b-4584-91ac-16044cb01da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, t.shape, u[\"c\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51b11e-f65c-4eae-a4e4-5387d9877ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t - T_star.flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d780b81-70bd-4e28-8fdd-5e3bf645757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star.flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765db79-84cc-47c7-8689-096a3a0ab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "\n",
    "layers = [4] + 10 * [5 * 50] + [5]\n",
    "\n",
    "# Load Data\n",
    "data = scipy.io.loadmat(\"data/Aneurysm3D.mat\")\n",
    "\n",
    "t_star = data[\"t_star\"]  # T x 1\n",
    "x_star = data[\"x_star\"]  # N x 1\n",
    "y_star = data[\"y_star\"]  # N x 1\n",
    "z_star = data[\"z_star\"]  # N x 1\n",
    "\n",
    "T = t_star.shape[0]\n",
    "N = x_star.shape[0]\n",
    "print(N)\n",
    "U_star = data[\"U_star\"]  # N x T\n",
    "V_star = data[\"V_star\"]  # N x T\n",
    "W_star = data[\"W_star\"]  # N x T\n",
    "P_star = data[\"P_star\"]  # N x T\n",
    "C_star = data[\"C_star\"]  # N x T\n",
    "\n",
    "# Rearrange Data\n",
    "T_star = np.tile(t_star, (1, N)).T  # N x T\n",
    "X_star = np.tile(x_star, (1, T))  # N x T\n",
    "Y_star = np.tile(y_star, (1, T))  # N x T\n",
    "Z_star = np.tile(z_star, (1, T))  # N x T\n",
    "\n",
    "T_data = T\n",
    "N_data = N\n",
    "idx_t = np.concatenate(\n",
    "    [np.array([0]), np.random.choice(T - 2, T_data - 2, replace=False) + 1, np.array([T - 1])]\n",
    ")\n",
    "print(idx_t)\n",
    "idx_x = np.random.choice(N, N_data, replace=False)\n",
    "t_data = T_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "x_data = X_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "y_data = Y_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "z_data = Z_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "c_data = C_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "\n",
    "T_eqns = T\n",
    "N_eqns = N\n",
    "idx_t = np.concatenate(\n",
    "    [np.array([0]), np.random.choice(T - 2, T_eqns - 2, replace=False) + 1, np.array([T - 1])]\n",
    ")\n",
    "idx_x = np.random.choice(N, N_eqns, replace=False)\n",
    "t_eqns = T_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "x_eqns = X_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "y_eqns = Y_star[:, idx_t][idx_x, :].flatten()[:, None]\n",
    "z_eqns = Z_star[:, idx_t][idx_x, :].flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e9ee7-5fdb-497f-9609-80ec85c2f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star.shape, t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15515d21-3f4c-4851-8a03-8519d2990aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4d9aa-a75a-4b11-83dd-900b9dc861be",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star[:, idx_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e40ec5-7c58-4b1c-945b-4cd851c29b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star[:, idx_t][idx_x, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f649f8e-d869-4c9b-9c6a-1200cb53e1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2stable",
   "language": "python",
   "name": "torch2stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
